{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb9c45e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import polars as pl\n",
    "import io\n",
    "import gc\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "from typing import Optional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1f78b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    \"\"\"Gère le téléchargement des données Binance\"\"\"\n",
    "    \n",
    "    def __init__(self, base_url: str, period: str = \"monthly\",\n",
    "                 target: str = \"aggTrades\", data_dir: str = \"./data\"):\n",
    "        self.base_url = base_url\n",
    "        self.period = period\n",
    "        self.target = target\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.data_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    def _get_filename(self, symbol: str, date: datetime) -> str:\n",
    "        \"\"\"Construit le nom de fichier selon le period\"\"\"\n",
    "        if self.period == \"monthly\":\n",
    "            return f'{symbol}-{self.target}-{date.year}-{date.month:02d}.csv'\n",
    "        elif self.period == \"daily\":\n",
    "            return f'{symbol}-{self.target}-{date.year}-{date.month:02d}-{date.day:02d}.csv'\n",
    "        else:\n",
    "            raise ValueError(f\"Period invalide: {self.period}\")\n",
    "    \n",
    "    def _get_url(self, symbol: str, date: datetime) -> str:\n",
    "        \"\"\"Construit l'URL de téléchargement\"\"\"\n",
    "        filename_base = self._get_filename(symbol, date).replace('.csv', '.zip')\n",
    "        return f\"{self.base_url}/{self.period}/{self.target}/{symbol}/{filename_base}\"\n",
    "    \n",
    "    def _download(self, url: str) -> bytes | None:\n",
    "        \"\"\"Télécharge un fichier ZIP\"\"\"\n",
    "        try:\n",
    "            r = requests.get(url, timeout=30)\n",
    "            return r.content if r.status_code == 200 else None\n",
    "        except (requests.RequestException, TimeoutError):\n",
    "            return None\n",
    "    \n",
    "    def _unzip(self, content: bytes, symbol: str, date: datetime) -> Path | None:\n",
    "        \"\"\"Décompresse un fichier ZIP et retourne le chemin du CSV\"\"\"\n",
    "        try:\n",
    "            with zipfile.ZipFile(io.BytesIO(content)) as z:\n",
    "                z.extractall(self.data_dir)\n",
    "            \n",
    "            csv_file = self.data_dir / self._get_filename(symbol, date)\n",
    "            return csv_file if csv_file.exists() else None\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur décompression: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def load(self, symbol: str, date: datetime) -> Path | None:\n",
    "        \"\"\"Charge un fichier (check existing → download → unzip)\"\"\"\n",
    "        # Check existing\n",
    "        csv_file = self.data_dir / self._get_filename(symbol, date)\n",
    "        if csv_file.exists():\n",
    "            return csv_file\n",
    "        \n",
    "        # Download\n",
    "        url = self._get_url(symbol, date)\n",
    "        content = self._download(url)\n",
    "        if not content:\n",
    "            return None\n",
    "        \n",
    "        # Unzip\n",
    "        return self._unzip(content, symbol, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaa24d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BarMethods:\n",
    "    \n",
    "    def __init__(self, df: pl.DataFrame,\n",
    "                 bar_params: dict = {'type': 'time', 'params': '5m'}):\n",
    "        self.df_raw = df\n",
    "        self.bar_params = bar_params\n",
    "        self._time_bar()\n",
    "\n",
    "    def _time_bar(self):\n",
    "        self.df_agg = (\n",
    "            self.df_raw\n",
    "            .group_by_dynamic('timestamp', every=self.bar_params.get('params', '5m'))\n",
    "            .agg([\n",
    "                pl.col('price').first().alias('open'),\n",
    "                pl.col('price').max().alias('high'),\n",
    "                pl.col('price').min().alias('low'),\n",
    "                pl.col('price').last().alias('close'),\n",
    "                pl.col('quantity').sum().alias('volume'),\n",
    "                pl.col('buy_volume').sum().alias('buy_volume'),\n",
    "                pl.col('sell_volume').sum().alias('sell_volume'),\n",
    "            ])\n",
    "            .with_columns([\n",
    "                (pl.col('buy_volume') - pl.col('sell_volume')).alias('delta'),\n",
    "                (pl.col('buy_volume') + pl.col('sell_volume')).alias('total_volume')\n",
    "            ])\n",
    "            .with_columns([\n",
    "                (pl.col('delta') / pl.col('total_volume')).alias('imbalance'),\n",
    "                pl.col('delta').cum_sum().alias('cvd')\n",
    "            ])\n",
    "        )\n",
    "\n",
    "class DataProcessor:\n",
    "    \"\"\"Traite, agrège et sauvegarde les données\"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir: str,\n",
    "                 bar_params: dict = {'type': 'time', 'params': '5m'}):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.data_dir.mkdir(exist_ok=True)\n",
    "        self.bar_params = bar_params\n",
    "    \n",
    "    def _preprocess(self, df: pl.DataFrame) -> pl.DataFrame:\n",
    "        \"\"\"Prépare les données brutes\"\"\"\n",
    "        return df.with_columns([\n",
    "            pl.from_epoch(pl.col('transact_time'), time_unit='ms').alias('timestamp'),\n",
    "            pl.col('price').cast(pl.Float64),\n",
    "            pl.col('quantity').cast(pl.Float64),\n",
    "            pl.when(~pl.col('is_buyer_maker')).then(pl.col('quantity')).otherwise(0).alias('buy_volume'),\n",
    "            pl.when(pl.col('is_buyer_maker')).then(pl.col('quantity')).otherwise(0).alias('sell_volume'),\n",
    "            (pl.col('price') * pl.col('quantity')).alias('dollar_volume')\n",
    "        ]).with_columns([\n",
    "            pl.col('quantity').cum_sum().alias('cumulative_volume'),\n",
    "            pl.col('dollar_volume').cum_sum().alias('cumulative_dollar')\n",
    "        ])\n",
    "    \n",
    "    def _clear(self, filepath: Path, *objects):\n",
    "        \"\"\"Libère la mémoire et supprime le CSV\"\"\"\n",
    "        # Supprimer le CSV source\n",
    "        if filepath.exists():\n",
    "            filepath.unlink()\n",
    "        \n",
    "        # Libérer les objets\n",
    "        for obj in objects:\n",
    "            del obj\n",
    "        gc.collect()\n",
    "    \n",
    "    def execute(self, filepath: Path, symbol: str, date: datetime):\n",
    "        \"\"\"Pipeline complet: read → preprocess → aggregate → save → clear\"\"\"\n",
    "        \n",
    "        # Read\n",
    "        df = pl.read_csv(\n",
    "            filepath,\n",
    "            has_header=False,\n",
    "            new_columns=['agg_trade_id', 'price', 'quantity', \n",
    "                       'first_trade_id', 'last_trade_id', \n",
    "                       'transact_time', 'is_buyer_maker']\n",
    "        )\n",
    "        \n",
    "        # Preprocess\n",
    "        df_prep = self._preprocess(df)\n",
    "        \n",
    "        # Aggregate\n",
    "        bar_methods = BarMethods(df_prep, bar_params=self.bar_params)\n",
    "        df_agg = bar_methods.df_agg\n",
    "        \n",
    "        # Save\n",
    "        bar_str = self.bar_params.get('params', '5m')\n",
    "        filename = self.data_dir / f\"{symbol}_{bar_str}_{date.year}-{date.month:02d}.parquet\"\n",
    "        df_agg.write_parquet(filename)\n",
    "        print(f\"→ {filename.name} ({len(df_agg)} barres)\")\n",
    "        \n",
    "        # Clear\n",
    "        self._clear(filepath, df, df_prep, df_agg, bar_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd61b4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import gc\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "SYMBOLS = ['BTCUSDT', 'ETHUSDT']\n",
    "START = datetime(2024, 1, 1)\n",
    "END = datetime(2024, 12, 31)\n",
    "\n",
    "# ============================================================================\n",
    "# INITIALISATION\n",
    "# ============================================================================\n",
    "BASE_URL = \"https://data.binance.vision/data/futures/um\"\n",
    "DATA_DIR = \"./data\"\n",
    "SYMBOL = \"BTCUSDT\"\n",
    "date = datetime(2024, 1, 1)\n",
    "\n",
    "\n",
    "\n",
    "loader = DataLoader(\n",
    "    base_url=\"https://data.binance.vision/data/futures/um\",\n",
    "    period=\"monthly\",\n",
    "    target=\"aggTrades\",\n",
    "    data_dir=DATA_DIR\n",
    ")\n",
    "csv_file = loader.load(SYMBOL, date)\n",
    "if csv_file:    \n",
    "    processor = DataProcessor(data_dir=DATA_DIR, bar_params={'type': 'time', 'params': '5m'})\n",
    "    processor.execute(filepath=csv_file, symbol=SYMBOL, date=date)\n",
    "else:\n",
    "    print(\"✗ Fichier non disponible\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csyst",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
